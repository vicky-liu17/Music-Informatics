{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwa6BxGwmGtr"
      },
      "source": [
        "# **Get Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pmfosigzy8Ea"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from scipy.io import wavfile\n",
        "import numpy as np\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5krTKWvyUD7",
        "outputId": "871fe9f4-883a-4a82-fc84-4e63a23ea7aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files in 'train' folder (MUS/train): ['MAPS_MUS-mond_2_SptkBGCl.wav', 'MAPS_MUS-gra_esp_3_SptkBGCl.txt', 'MAPS_MUS-mz_331_1_SptkBGCl.wav', 'MAPS_MUS-chpn-p2_SptkBGCl.txt', 'MAPS_MUS-liz_et4_SptkBGCl.mid', 'MAPS_MUS-bk_xmas2_SptkBGCl.txt', 'MAPS_MUS-mond_2_SptkBGCl.txt', 'MAPS_MUS-gra_esp_3_SptkBGCl.wav', 'MAPS_MUS-mz_331_1_SptkBGCl.txt', 'MAPS_MUS-chpn-p2_SptkBGCl.wav', 'MAPS_MUS-bk_xmas2_SptkBGCl.wav', 'MAPS_MUS-alb_esp6_SptkBGCl.txt', 'MAPS_MUS-bk_xmas4_SptkBGCl.txt', 'MAPS_MUS-br_im5_SptkBGCl.mid', 'MAPS_MUS-mz_330_1_SptkBGCl.txt', 'MAPS_MUS-bach_847_SptkBGCl.mid', 'MAPS_MUS-alb_esp6_SptkBGCl.wav', 'MAPS_MUS-bk_xmas4_SptkBGCl.wav', 'MAPS_MUS-mz_330_1_SptkBGCl.wav', 'MAPS_MUS-mond_2_SptkBGCl.mid', 'MAPS_MUS-mz_331_1_SptkBGCl.mid', 'MAPS_MUS-liz_et4_SptkBGCl.wav', 'MAPS_MUS-gra_esp_3_SptkBGCl.mid', 'MAPS_MUS-chpn-p2_SptkBGCl.mid', 'MAPS_MUS-liz_et4_SptkBGCl.txt', 'MAPS_MUS-bk_xmas2_SptkBGCl.mid', 'MAPS_MUS-br_im5_SptkBGCl.wav', 'MAPS_MUS-bach_847_SptkBGCl.wav', 'MAPS_MUS-alb_esp6_SptkBGCl.mid', 'MAPS_MUS-bk_xmas4_SptkBGCl.mid', 'MAPS_MUS-br_im5_SptkBGCl.txt', 'MAPS_MUS-mz_330_1_SptkBGCl.mid', 'MAPS_MUS-bach_847_SptkBGCl.txt', 'MAPS_MUS-grieg_walzer_SptkBGCl.mid', 'MAPS_MUS-chpn_op27_2_SptkBGCl.mid', 'MAPS_MUS-muss_3_SptkBGCl.mid', 'MAPS_MUS-chpn-p6_SptkBGCl.mid', 'MAPS_MUS-pathetique_1_SptkBGCl.mid', 'MAPS_MUS-liz_rhap09_SptkBGCl.mid', 'MAPS_MUS-chpn-p7_SptkBGCl.mid', 'MAPS_MUS-burg_perlen_SptkBGCl.mid', 'MAPS_MUS-appass_1_SptkBGCl.mid', 'MAPS_MUS-alb_esp2_SptkBGCl.mid', 'MAPS_MUS-alb_esp5_SptkBGCl.mid', 'MAPS_MUS-grieg_walzer_SptkBGCl.txt', 'MAPS_MUS-muss_3_SptkBGCl.txt', 'MAPS_MUS-chpn_op27_2_SptkBGCl.txt', 'MAPS_MUS-chpn-p6_SptkBGCl.txt', 'MAPS_MUS-grieg_walzer_SptkBGCl.wav', 'MAPS_MUS-muss_3_SptkBGCl.wav', 'MAPS_MUS-chpn_op27_2_SptkBGCl.wav', 'MAPS_MUS-chpn-p6_SptkBGCl.wav', 'MAPS_MUS-chpn-p7_SptkBGCl.txt', 'MAPS_MUS-burg_perlen_SptkBGCl.txt', 'MAPS_MUS-pathetique_1_SptkBGCl.wav', 'MAPS_MUS-liz_rhap09_SptkBGCl.wav', 'MAPS_MUS-appass_1_SptkBGCl.txt', 'MAPS_MUS-alb_esp2_SptkBGCl.txt', 'MAPS_MUS-alb_esp5_SptkBGCl.txt', 'MAPS_MUS-chpn-p7_SptkBGCl.wav', 'MAPS_MUS-burg_perlen_SptkBGCl.wav', 'MAPS_MUS-pathetique_1_SptkBGCl.txt', 'MAPS_MUS-liz_rhap09_SptkBGCl.txt', 'MAPS_MUS-alb_esp2_SptkBGCl.wav', 'MAPS_MUS-appass_1_SptkBGCl.wav', 'MAPS_MUS-alb_esp5_SptkBGCl.wav']\n",
            "Files in 'test' folder (MUS/test): ['MAPS_MUS-scn16_4_SptkBGCl.txt', 'MAPS_MUS-scn16_4_SptkBGCl.wav', 'MAPS_MUS-ty_november_SptkBGCl.txt', 'MAPS_MUS-schub_d960_3_SptkBGCl.wav', 'MAPS_MUS-scn15_5_SptkBGCl.mid', 'MAPS_MUS-ty_november_SptkBGCl.wav', 'MAPS_MUS-schub_d960_3_SptkBGCl.txt', 'MAPS_MUS-scn16_4_SptkBGCl.mid', 'MAPS_MUS-scn15_5_SptkBGCl.txt', 'MAPS_MUS-schub_d960_3_SptkBGCl.mid', 'MAPS_MUS-scn15_5_SptkBGCl.wav', 'MAPS_MUS-ty_november_SptkBGCl.mid']\n",
            "Files in 'validation' folder (MUS/validation): ['MAPS_MUS-ty_februar_SptkBGCl.mid', 'MAPS_MUS-scn16_2_SptkBGCl.txt', 'MAPS_MUS-scn15_2_SptkBGCl.mid', 'MAPS_MUS-scn16_2_SptkBGCl.wav', 'MAPS_MUS-ty_februar_SptkBGCl.txt', 'MAPS_MUS-ty_februar_SptkBGCl.wav', 'MAPS_MUS-scn15_2_SptkBGCl.txt', 'MAPS_MUS-scn15_2_SptkBGCl.wav', 'MAPS_MUS-scn16_2_SptkBGCl.mid', 'MAPS_MUS-waldstein_3_SptkBGCl.mid', 'MAPS_MUS-waldstein_3_SptkBGCl.txt', 'MAPS_MUS-waldstein_3_SptkBGCl.wav']\n"
          ]
        }
      ],
      "source": [
        "# Define the folder paths for training, testing, and validation files\n",
        "folder_path_train = \"MUS/train\"\n",
        "folder_path_test = \"MUS/test\"\n",
        "folder_path_validation = \"MUS/validation\"\n",
        "\n",
        "# Check and list files in the training folder\n",
        "if os.path.exists(folder_path_train) and os.path.isdir(folder_path_train):\n",
        "    files_train = os.listdir(folder_path_train)\n",
        "    print(f\"Files in 'train' folder ({folder_path_train}):\", files_train)\n",
        "else:\n",
        "    print(f\"The folder '{folder_path_train}' does not exist or is not a directory.\")\n",
        "    files_train = []  # Assign empty list if folder doesn't exist\n",
        "\n",
        "# Check and list files in the testing folder\n",
        "if os.path.exists(folder_path_test) and os.path.isdir(folder_path_test):\n",
        "    files_test = os.listdir(folder_path_test)\n",
        "    print(f\"Files in 'test' folder ({folder_path_test}):\", files_test)\n",
        "else:\n",
        "    print(f\"The folder '{folder_path_test}' does not exist or is not a directory.\")\n",
        "    files_test = []  # Assign empty list if folder doesn't exist\n",
        "\n",
        "# Check and list files in the validation folder\n",
        "if os.path.exists(folder_path_validation) and os.path.isdir(folder_path_validation):\n",
        "    files_val = os.listdir(folder_path_validation)\n",
        "    print(f\"Files in 'validation' folder ({folder_path_validation}):\", files_val)\n",
        "else:\n",
        "    print(f\"The folder '{folder_path_validation}' does not exist or is not a directory.\")\n",
        "    files_val = []  # Assign empty list if folder doesn't exist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UuXW1upmMrB"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "EsXePUSs3iN9"
      },
      "outputs": [],
      "source": [
        "# Constants for processing parameters\n",
        "HOP_LENGTH = 512\n",
        "N_BINS = 252\n",
        "BINS_PER_OCTAVE = 36\n",
        "NUM_NOTES = 88\n",
        "MAX_SAMPLES_PER_FILE = 4000000\n",
        "\n",
        "# Training, validation, and test sets\n",
        "train_features, train_labels = [], []\n",
        "val_features, val_labels = [], []\n",
        "test_features, test_labels = [],[]\n",
        "train_count = 0\n",
        "val_count = 0\n",
        "test_count = 0\n",
        "\n",
        "def preprocess(files, feature_storage, label_storage, count, folder_path, type):\n",
        "    \"\"\"\n",
        "    Processes a list of audio files, extracts their CQT features, aligns them with ground truth labels,\n",
        "    and stores them in feature and label storage lists.\n",
        "\n",
        "    Args:\n",
        "        files (list): List of file names to process.\n",
        "        feature_storage (list): The list to store CQT features.\n",
        "        label_storage (list): The list to store label matrices.\n",
        "        count (int): Counter to keep track of the number of files processed.\n",
        "        folder_path (str): Path to the folder containing the audio files.\n",
        "\n",
        "    Returns:\n",
        "        int: The updated count of processed files.\n",
        "    \"\"\"\n",
        "    for filename in files:\n",
        "        # Load audio file and calculate window length\n",
        "        if not filename.lower().endswith('.wav'):\n",
        "            continue\n",
        "        \n",
        "        full_file_path = os.path.join(folder_path, filename)\n",
        "        sampling_freq, stereo_vector = wavfile.read(full_file_path)\n",
        "        \n",
        "        # If audio is stereo (ndim == 2), convert to mono by averaging channels\n",
        "        if stereo_vector.ndim == 2:\n",
        "            stereo_vector = stereo_vector.mean(axis=1)\n",
        "\n",
        "        # Ensure Fortran-contiguous format for librosa\n",
        "        float_array = np.asfortranarray(stereo_vector / 1.0)\n",
        "\n",
        "        # Extract CQT features\n",
        "        try:\n",
        "            cqt_features = np.abs(librosa.cqt(float_array, sr=sampling_freq, hop_length=HOP_LENGTH, \n",
        "                                              n_bins=N_BINS, bins_per_octave=BINS_PER_OCTAVE)).T\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {filename}: {e}\")\n",
        "            continue  # Skip the file if there's an issue\n",
        "\n",
        "        # Determine the number of frames and create a time vector\n",
        "        num_frames = cqt_features.shape[0]\n",
        "        window_length = HOP_LENGTH / float(sampling_freq)\n",
        "        time_vector = np.arange(1, num_frames + 1) * window_length\n",
        "\n",
        "        # Initialize binary label matrix with dimensions (frames, notes)\n",
        "        labels = np.zeros((num_frames, NUM_NOTES))\n",
        "\n",
        "        # Read and process aligned labels from the corresponding text file\n",
        "        folder_path_label = \"MUS/\"+type\n",
        "        label_file_path = os.path.join(folder_path_label, f\"{filename.split('.')[0]}.txt\")\n",
        "        try:\n",
        "            with open(label_file_path, \"r\") as file:\n",
        "                lines = file.readlines()[1:]  # Skip the first line (header)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Label file not found for {filename}, skipping.\")\n",
        "            continue  # Skip if the label file does not exist\n",
        "\n",
        "        for line in lines:\n",
        "            if line.strip():\n",
        "                try:\n",
        "                    start, end, pitch = map(float, line.split('\\t')[:3])\n",
        "                    pitch = int(pitch) - 21\n",
        "                    start_idx = np.where(time_vector >= start)[0]\n",
        "                    end_idx = np.where(time_vector > end)[0]\n",
        "\n",
        "                    if start_idx.size and end_idx.size:\n",
        "                        labels[start_idx[0]:end_idx[0], pitch] = 1\n",
        "                except ValueError:\n",
        "                    print(f\"Error parsing line: {line}\")\n",
        "                    continue\n",
        "\n",
        "        # Ensure files don't exceed the maximum allowed samples per file\n",
        "        while (len(feature_storage) + len(cqt_features)) >= MAX_SAMPLES_PER_FILE:\n",
        "            to_add = MAX_SAMPLES_PER_FILE - len(feature_storage)\n",
        "            feature_storage.extend(cqt_features[:to_add, :])\n",
        "            label_storage.extend(labels[:to_add, :])\n",
        "\n",
        "            feature_storage_np = np.array(feature_storage)\n",
        "            label_storage_np = np.array(label_storage)\n",
        "\n",
        "            count += 1\n",
        "            feature_storage = []\n",
        "            label_storage = []\n",
        "            cqt_features = cqt_features[to_add:, :]\n",
        "            labels = labels[to_add:, :]\n",
        "\n",
        "        # Add remaining CQT features and labels if less than the max allowed\n",
        "        if len(cqt_features) == MAX_SAMPLES_PER_FILE:\n",
        "            feature_storage.extend(cqt_features)\n",
        "            label_storage.extend(labels)\n",
        "            feature_storage_np = np.array(feature_storage)\n",
        "            label_storage_np = np.array(label_storage)\n",
        "\n",
        "            count += 1\n",
        "            feature_storage = []\n",
        "            label_storage = []\n",
        "        elif len(cqt_features) > 0:\n",
        "            feature_storage.extend(cqt_features)\n",
        "            label_storage.extend(labels)\n",
        "\n",
        "    return count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "0oU9BW-34ift"
      },
      "outputs": [],
      "source": [
        "train_count = preprocess(files_train, train_features, train_labels, train_count, folder_path_train,\"train\")\n",
        "test_count = preprocess(files_test, test_features, test_labels, test_count, folder_path_test,\"test\")\n",
        "val_count = preprocess(files_val, val_features, val_labels, val_count, folder_path_validation,\"validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3nb7Q594-Th",
        "outputId": "2b9e1d76-6dbe-42ae-9382-060c2dc9db67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1002404 1002404\n",
            "120046 120046\n",
            "214852 214852\n"
          ]
        }
      ],
      "source": [
        "print(len(train_features), len(train_labels))\n",
        "print(len(test_features), len(test_labels))\n",
        "print(len(val_features), len(val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.26247715 3.34382455 4.193564   1.21715206 2.56971742 3.92374946\n",
            " 2.62094867 0.49291579 1.83522757 1.97284751 1.24932324 0.22804384\n",
            " 0.60954276 0.84884565 0.68742419 0.38717084 0.10932005 0.20133487\n",
            " 0.38653377 0.19615492 0.07954734 0.05405585 0.05381713 0.07940027\n",
            " 0.22942333 0.1004976  0.25170722 0.21345577 0.08918274 0.11633008\n",
            " 0.12876456 0.23205345 0.09492521 0.40929257 0.1622173  0.1742389\n",
            " 0.11214504 0.38406738 0.08026482 0.37651087 0.52047902 0.3553573\n",
            " 0.23245577 0.55621974 0.54132612 0.51501621 0.58460044 0.48808568\n",
            " 0.14209117 0.64718753 0.83478702 0.53035571 0.40087926 0.52906981\n",
            " 0.72820123 1.27839933 1.07559764 0.34710241 0.64346272 1.73411278\n",
            " 1.01550131 2.03847055 1.96620169 1.00971576 0.53550953 0.36454564\n",
            " 1.4919704  0.89495478 3.31558091 2.97018455 1.28069179 0.64816916\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.        ]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "print(val_features[1])\n",
        "print(val_labels[3128])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdkOPMIT8EJG"
      },
      "source": [
        "# Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KA43C5u8F8j",
        "outputId": "c7943e9c-f8d6-46a1-8ce6-32207b27ec9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.0, 201740.499183033)"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the minimum and maximum values from the X values in the training set\n",
        "max_train = max(max(val) for val in train_features)\n",
        "min_train = min(min(val) for val in train_features)\n",
        "min_train, max_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "4rxcF0VL8MO6"
      },
      "outputs": [],
      "source": [
        "# Normalize each X value in the training set for every single frame (but this one hasnt taken into account the mean)\n",
        "initial_norm_train_features = [[(x - min_train) / (max_train - min_train) for x in inner_list] for inner_list in train_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "YQ_4EuoI8jCs"
      },
      "outputs": [],
      "source": [
        "# Calculate the mean of the normalized values\n",
        "flattened_normalized_X_train = [value for sublist in initial_norm_train_features for value in sublist]\n",
        "train_mean = sum(flattened_normalized_X_train) / len(flattened_normalized_X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBxhJgiy8uC6",
        "outputId": "7cc547af-477b-463d-bc81-ed880c0f8a1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.005631972873553208"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "eVS7R3Tn8mcB"
      },
      "outputs": [],
      "source": [
        "# Normalize each X value in the training set for every single frame\n",
        "norm_train_X = [[value - train_mean for value in sublist] for sublist in initial_norm_train_features]\n",
        "\n",
        "# Normalize each X value in the validation set for every single frame\n",
        "norm_val_X = [[value - train_mean for value in sublist] for sublist in val_features]\n",
        "\n",
        "# Normalize each X value in the test set for every single frame\n",
        "norm_test_X = [[value - train_mean for value in sublist] for sublist in test_features]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3PJ28uyGdVv"
      },
      "source": [
        "# Baseline Log Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "jR6ETxffGdVw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, multilabel_confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "pMA89brHGdVw",
        "outputId": "63785f0e-ef3a-4658-ae55-3c0ad2b5dcfd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 0 is present in all training examples.\n",
            "  warnings.warn(\"Label %s is present in all training examples.\" %\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 1 is present in all training examples.\n",
            "  warnings.warn(\"Label %s is present in all training examples.\" %\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 2 is present in all training examples.\n",
            "  warnings.warn(\"Label %s is present in all training examples.\" %\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 83 is present in all training examples.\n",
            "  warnings.warn(\"Label %s is present in all training examples.\" %\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 84 is present in all training examples.\n",
            "  warnings.warn(\"Label %s is present in all training examples.\" %\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 85 is present in all training examples.\n",
            "  warnings.warn(\"Label %s is present in all training examples.\" %\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 86 is present in all training examples.\n",
            "  warnings.warn(\"Label %s is present in all training examples.\" %\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/multiclass.py:76: UserWarning: Label not 87 is present in all training examples.\n",
            "  warnings.warn(\"Label %s is present in all training examples.\" %\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "OneVsRestClassifier(estimator=LogisticRegression(solver='saga', tol=0.01))"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Training data\n",
        "X_train = np.array(norm_train_X)\n",
        "y_train = np.array(train_labels)\n",
        "\n",
        "model = OneVsRestClassifier(LogisticRegression(solver='saga', tol=0.01, max_iter=100))\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "4HnI83ZXGdVw"
      },
      "outputs": [],
      "source": [
        "# Testing set\n",
        "X_test = np.array(norm_test_X)\n",
        "y_test = np.array(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "Gncr07EMGdVw"
      },
      "outputs": [],
      "source": [
        "# Making Prediction\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzZ--bwEGdVx",
        "outputId": "c790ed40-b27a-42bc-ddd8-b3d96c771a16"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.07      1.00      0.13      3336\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.04      0.73      0.08       816\n",
            "           9       0.00      1.00      0.00        32\n",
            "          10       0.09      0.95      0.17      1206\n",
            "          11       0.03      0.96      0.07       698\n",
            "          12       0.28      0.95      0.44      6366\n",
            "          13       0.09      0.99      0.17      3116\n",
            "          14       0.08      0.87      0.14      1236\n",
            "          15       0.32      0.94      0.47      3894\n",
            "          16       0.09      0.82      0.17       986\n",
            "          17       0.19      0.95      0.32      6988\n",
            "          18       0.14      1.00      0.24      1684\n",
            "          19       0.65      0.86      0.74      5256\n",
            "          20       0.12      0.99      0.21      3170\n",
            "          21       0.14      0.99      0.25      4290\n",
            "          22       0.34      0.89      0.49      3090\n",
            "          23       0.17      0.90      0.29      2988\n",
            "          24       0.37      0.97      0.53     10242\n",
            "          25       0.24      0.99      0.39      8290\n",
            "          26       0.49      0.98      0.66      6284\n",
            "          27       0.42      0.93      0.57      8662\n",
            "          28       0.30      0.93      0.46      6778\n",
            "          29       0.33      0.82      0.47     12104\n",
            "          30       0.23      0.99      0.37      5760\n",
            "          31       0.50      0.96      0.66      9080\n",
            "          32       0.40      0.96      0.56     10876\n",
            "          33       0.55      0.85      0.67     13658\n",
            "          34       0.59      0.89      0.71     11096\n",
            "          35       0.34      0.88      0.49      8986\n",
            "          36       0.57      0.76      0.65     21962\n",
            "          37       0.45      0.93      0.60     18592\n",
            "          38       0.51      0.85      0.64     12734\n",
            "          39       0.58      0.85      0.69     15336\n",
            "          40       0.56      0.98      0.71     15710\n",
            "          41       0.56      0.91      0.69     15984\n",
            "          42       0.48      0.95      0.64     16966\n",
            "          43       0.51      0.87      0.64     12768\n",
            "          44       0.44      0.93      0.60     14728\n",
            "          45       0.46      0.92      0.62     13238\n",
            "          46       0.48      0.92      0.63     12948\n",
            "          47       0.35      0.82      0.49      9676\n",
            "          48       0.41      0.87      0.56     14270\n",
            "          49       0.25      0.95      0.40      8298\n",
            "          50       0.34      0.90      0.50     10082\n",
            "          51       0.20      0.77      0.32      7114\n",
            "          52       0.23      0.81      0.36      8686\n",
            "          53       0.21      0.86      0.33      8536\n",
            "          54       0.24      0.96      0.38      7656\n",
            "          55       0.37      0.85      0.51      7580\n",
            "          56       0.18      0.95      0.30      4326\n",
            "          57       0.10      0.89      0.18      4080\n",
            "          58       0.12      0.88      0.21      3932\n",
            "          59       0.21      0.95      0.35      6392\n",
            "          60       0.12      0.89      0.21      4656\n",
            "          61       0.14      0.98      0.24      4376\n",
            "          62       0.19      0.94      0.32      4478\n",
            "          63       0.15      0.81      0.26      2642\n",
            "          64       0.06      0.98      0.12      1560\n",
            "          65       0.05      0.96      0.10      1804\n",
            "          66       0.04      0.93      0.09       846\n",
            "          67       0.02      0.99      0.04       292\n",
            "          68       0.00      0.00      0.00         0\n",
            "          69       0.01      1.00      0.02       254\n",
            "          70       0.07      0.94      0.13       820\n",
            "          71       0.01      1.00      0.02        62\n",
            "          72       0.03      0.99      0.05       392\n",
            "          73       0.02      0.94      0.04       520\n",
            "          74       0.00      0.00      0.00         0\n",
            "          75       0.00      0.00      0.00         0\n",
            "          76       0.00      0.00      0.00         0\n",
            "          77       0.00      0.00      0.00         0\n",
            "          78       0.00      0.00      0.00         0\n",
            "          79       0.00      0.00      0.00         0\n",
            "          80       0.00      0.00      0.00         0\n",
            "          81       0.00      0.00      0.00         0\n",
            "          82       0.00      0.00      0.00         0\n",
            "          83       0.00      0.00      0.00         0\n",
            "          84       0.00      0.00      0.00         0\n",
            "          85       0.00      0.00      0.00         0\n",
            "          86       0.00      0.00      0.00         0\n",
            "          87       0.00      0.00      0.00         0\n",
            "\n",
            "   micro avg       0.23      0.90      0.36    455264\n",
            "   macro avg       0.20      0.69      0.28    455264\n",
            "weighted avg       0.38      0.90      0.52    455264\n",
            " samples avg       0.25      0.85      0.37    455264\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "C7tSTPrHGdVx"
      },
      "outputs": [],
      "source": [
        "# Confusion matrices\n",
        "conf_matrices = multilabel_confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHsqJcKhGdVx",
        "outputId": "45609943-39bd-46e2-aaf0-15e740472ddd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total True Negatives (TN): 8714120\n",
            "Total False Positives (FP): 1394664\n",
            "Total False Negatives (FN): 44188\n",
            "Total True Positives (TP): 411076\n",
            "\n",
            "Accuracy: 0.222211891489831\n",
            "\n",
            "Recall: 0.902939832712448\n",
            "\n",
            "Precision: 0.227649606255607\n",
            "\n",
            "F-measure: 36.36\n"
          ]
        }
      ],
      "source": [
        "TN_total = conf_matrices[:, 0, 0].sum()\n",
        "FP_total = conf_matrices[:, 0, 1].sum()\n",
        "FN_total = conf_matrices[:, 1, 0].sum()\n",
        "TP_total = conf_matrices[:, 1, 1].sum()\n",
        "precision = TP_total / float(TP_total + FP_total)\n",
        "recall = TP_total / float(TP_total + FN_total)\n",
        "f1_score = 100 * 2 * precision * recall / (precision + recall)\n",
        "accuracy = TP_total / float(TP_total + FP_total + FN_total)\n",
        "\n",
        "print(f\"Total True Negatives (TN): {TN_total}\")\n",
        "print(f\"Total False Positives (FP): {FP_total}\")\n",
        "print(f\"Total False Negatives (FN): {FN_total}\")\n",
        "print(f\"Total True Positives (TP): {TP_total}\")\n",
        "\n",
        "print(f\"\\nAccuracy: {accuracy:.15f}\")\n",
        "\n",
        "print(f\"\\nRecall: {recall:.15f}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.15f}\")\n",
        "\n",
        "print(f\"\\nF-measure: {f1_score:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_single_audio(file_path):\n",
        "    \"\"\"\n",
        "    Processes a single audio file, extracts its CQT features.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the .wav file to process.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Extracted CQT features from the audio file.\n",
        "    \"\"\"\n",
        "    # Load the audio file\n",
        "    sampling_freq, stereo_vector = wavfile.read(file_path)\n",
        "\n",
        "    # If stereo (2D), convert to mono by averaging the channels\n",
        "    if len(stereo_vector.shape) == 2:\n",
        "        float_array = stereo_vector.mean(axis=1)  # Convert to mono by averaging channels\n",
        "    else:\n",
        "        float_array = stereo_vector\n",
        "\n",
        "    # Convert to float type and ensure Fortran-contiguity\n",
        "    float_array = float_array / 1.0\n",
        "    float_array = np.asfortranarray(float_array)  # Ensure Fortran contiguity\n",
        "\n",
        "    # Extract CQT features\n",
        "    cqt_features = np.abs(librosa.cqt(float_array, sr=sampling_freq, hop_length=HOP_LENGTH, n_bins=N_BINS, bins_per_octave=BINS_PER_OCTAVE)).T\n",
        "\n",
        "    return cqt_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1850, 252)\n",
            "[[2.17684854e+02 1.57981411e+02 1.47884884e+03 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [2.17604614e+02 1.60361315e+02 1.47921326e+03 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [2.17425644e+02 1.66343285e+02 1.48032090e+03 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " ...\n",
            " [4.95789456e+02 1.00039470e+03 4.62234693e+02 ... 3.11889514e+02\n",
            "  9.93173209e+02 4.86098692e+02]\n",
            " [4.97109182e+02 1.00095879e+03 4.44941630e+02 ... 5.32992270e+00\n",
            "  2.00924157e+00 2.55606982e+00]\n",
            " [4.97609825e+02 1.00117257e+03 4.38081383e+02 ... 1.21831726e+00\n",
            "  1.41130249e+00 1.27370883e+00]]\n"
          ]
        }
      ],
      "source": [
        "cqt_features = preprocess_single_audio(\"sample/bee.wav\")\n",
        "print(cqt_features.shape) \n",
        "print(cqt_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1850, 252)\n",
            "[[6.48963131e-04 4.70974941e-04 4.40875126e-03 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [6.48723920e-04 4.78069922e-04 4.40983766e-03 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " [6.48190374e-04 4.95903398e-04 4.41313978e-03 ... 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00]\n",
            " ...\n",
            " [1.47804991e-03 2.98238148e-03 1.37801628e-03 ... 9.29806518e-04\n",
            "  2.96085274e-03 1.44915975e-03]\n",
            " [1.48198428e-03 2.98406314e-03 1.32646212e-03 ... 1.58895911e-05\n",
            "  5.98996061e-06 7.62016763e-06]\n",
            " [1.48347680e-03 2.98470048e-03 1.30601032e-03 ... 3.63205326e-06\n",
            "  4.20738175e-06 3.79718687e-06]]\n",
            "(1850, 252)\n",
            "[[-0.99870207 -0.99905805 -0.9911825  ... -1.         -1.\n",
            "  -1.        ]\n",
            " [-0.99870255 -0.99904386 -0.99118032 ... -1.         -1.\n",
            "  -1.        ]\n",
            " [-0.99870362 -0.99900819 -0.99117372 ... -1.         -1.\n",
            "  -1.        ]\n",
            " ...\n",
            " [-0.9970439  -0.99403524 -0.99724397 ... -0.99814039 -0.99407829\n",
            "  -0.99710168]\n",
            " [-0.99703603 -0.99403187 -0.99734708 ... -0.99996822 -0.99998802\n",
            "  -0.99998476]\n",
            " [-0.99703305 -0.9940306  -0.99738798 ... -0.99999274 -0.99999159\n",
            "  -0.99999241]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "cqt_min = np.min(cqt_features)\n",
        "cqt_max = np.max(cqt_features)\n",
        "\n",
        "cqt_features_normalized = (cqt_features - cqt_min) / (cqt_max - cqt_min)\n",
        "\n",
        "print(cqt_features_normalized.shape)\n",
        "print(cqt_features_normalized)\n",
        "\n",
        "cqt_features_normalized = 2 * (cqt_features - cqt_min) / (cqt_max - cqt_min) - 1\n",
        "\n",
        "print(cqt_features_normalized.shape)\n",
        "print(cqt_features_normalized)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
